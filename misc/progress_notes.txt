10-12-2022
- For Fitbit API, although there are some existing OAuth 2.0 Library for Python, I decided not to use it and create my own Fitbit class instead for my learning purpose.
    - Because of that, it took me a long time to figure out how to authorize and fetch some data via Fitbit API, especially to realize that the parameters such as client_id or authorization_token need to be passed to requests.post() function via the 'data' parameter and not the 'params'.
- There is a feature called Fitbit Subscribe to get notifed when the Fitbit data is updated by the user, but I chose to use a scheduling tool like Airflow for my learning purpose.
- I was able to authorize, get access token, and fetch Fitbit data regarding my sleep via Fitbit API.

~10-18-2022
- Started encapsulating the Fitbit API related functions to a Fitbit class.
- With the recommended "Authorization Code Grant Flow with PKCE", the authorization process needs to be done using a web browser. And the provided authorization code expires in 10min.
    - So I cannot just run a Python program every day with some scheduling tool to fethch my Fitbit data becasue I, as a Fitbit user, need to approve the access to my data on some web browser first.
    - To overcome this, in my questionnaire that I'll answer every day, include the URL for the authorization and provide the given authorization code through the questionnaire answer?
    - But with this approach, the Python program to extract the Fitbit data needs to wait for me to complete the questionnaire
- With the "Implicit Grant Flow", I can choose the expiration period of the access token, so once I allowed Fitbit to grant acceess, I can access the Fitbit data using the same access token for the specified period of time.
    - But to allow the access to my Fitbit data and provide the access code at first, I still need to use a web browser.
- For the purpose of this project, I want to make it fully automated, so I will try the "Implicit Grant Flow".

10-19-2022
- Tried different Fitbit APIs
- Decided to use RDS instead of Redshift because Redshift is so expensive, RDS offers free tier for a longer period of time (12 months vs 2 months), and there shouldn't be so much data that it requires an actual data warehouse solution like Redshift.
    - Redshift is based on PostgreSQL, so I will use RDS PostgreSQL.
- Tested loading the extracted Fitbit data in json format into an RDS PostgreSQL instance using psycopg2
    - Those data in json format will be parsed and transformed later using dbt
    - These json data will land in LANDING, be parsed in STAGING, and be transformed and stored in PROD databases
- Testing json data parse


10-20-2022
- For the sleep level data (light, rem, etc..), although I aggregated the "sleep : levels : data" and "sleep : levels : shortData", I wasn't able to get the same values as the "sleep : levels : summary".
    - It was because of this: https://www.fitabase.com/resources/knowledge-base/learn-about-fitbit-data/sleep-stage-data/
    - During one single light sleep (59min), there were 4 wakes like below, and that's why this light sleep was actually counted 4 times:

    "2022-10-11T03:48:30.000"	"light"	59
    "2022-10-11T03:52:30.000"	"wake"	1
    "2022-10-11T03:57:30.000"	"wake"	0
    "2022-10-11T04:03:00.000"	"wake"	1
    "2022-10-11T04:43:30.000"	"wake"	0

    - So simple aggregation cannot get the same results as the summary.
- Parsed and aggregated the sleep level data so that the aggregated results match the "sleep : levels : summary" (= solved the issue above).


11-03-2022
- Changed the schema design. Now, there is only one database 'Fitbit_Analysis' with 3 schemas (LANDING, STAGING, PROD) in it.
- Wrote the sql to parse Fitbit steps data

11-07-2022
- Started setting up airflow on EC2 instance

12-19-2022
- Continue working on airflow set-up
- Set up a RDS PostgreSQL as an Airflow metadata database
- Start wrting dags

~ 12-22-2022
- Done Fitbit extract & load using Airflow
- Start setting up dbt with Airflow

12-25-2022
- Done dbt setup
- Tested simple Fitbit data ELT on Airflow

12-26-2022
- Started exploring Google Forms for my questionaaire
- Finalizing the data model in my data warehouse

~12-30-2022
- Add more fitbit data... distance, sedentary, and heartrate


~01-05-2023
- Change the Fitbit aggregation interval from 30min to 1h

~01-16-2023
- Create a new staging data model to store the sleep daily summary
- For Fitbit sleep data, there are duplicate records after left join.
    - "left join cte_add_endTime b on b.level_start > a.level_start and b.level_start < a.level_end"
    - examples:
        "38696570769"	"light"	"2022-10-11 03:48:30"	"2022-10-11 04:47:30"	3540	"wake"	"2022-10-11 03:52:30"	"2022-10-11 03:54:00"	90
        "38696570769"	"light"	"2022-10-11 03:48:30"	"2022-10-11 04:47:30"	3540	"wake"	"2022-10-11 03:57:30"	"2022-10-11 03:58:00"	30
        "38696570769"	"light"	"2022-10-11 03:48:30"	"2022-10-11 04:47:30"	3540	"wake"	"2022-10-11 04:03:00"	"2022-10-11 04:04:00"	60
        "38696570769"	"light"	"2022-10-11 03:48:30"	"2022-10-11 04:47:30"	3540	"wake"	"2022-10-11 04:43:30"	"2022-10-11 04:44:00"	30
        "38696570769"	"wake"	"2022-10-11 03:52:30"	"2022-10-11 03:54:00"	90				
        "38696570769"	"wake"	"2022-10-11 03:57:30"	"2022-10-11 03:58:00"	30				
        "38696570769"	"wake"	"2022-10-11 04:03:00"	"2022-10-11 04:04:00"	60				

~01-19-2023
- All houly aggregations are for the hour before the time
    - 00:00:00 ~ 00:59:00 data are aggregated to 01:00:00
- Wrote 3 sleep data models
- Change the if_incremental() logics in all models